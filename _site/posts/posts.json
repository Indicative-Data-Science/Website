[
  {
    "path": "posts/2021-04-22-osdeveloper/",
    "title": "How to detect 3D buildings using GNSS data: An Ordnancy Survey Blog",
    "description": {},
    "author": [
      {
        "name": "Terrence Lines",
        "url": {
          "https://www.gla.ac.uk/schools/ges/staff/terencelines/": {}
        }
      }
    ],
    "date": "2021-04-22",
    "categories": [
      "GNSS-Mapping"
    ],
    "contents": "\nOrdnance Survey\nOrdnance Survey, the UK’s mapping agency, is a partner on our project to explore new techniques to build 3D maps of towns and cities. We explain how their expanded abilities to provide mapping data helps our project.\nOur team at the University of Glasgow researches cutting-edge approaches to utilising geospatial data. With modern big data, often the data that you are missing is as important as the data you have. For example, we’re using missing GPS signals to build 3D maps of cities.\nBackground\n Photo: ©GSA, ©European GNSS Agency.\nModern phones use GPS signals to position themselves, receiving signals from many orbiting satellites. Only a few satellites are used to calculate your position, with the additional satellites needed to provide redundancy as their signals can be easily blocked. These blockages are caused by obstacles such as buildings. By analysing the patterns of blockages from many phones, we are able to generate 3D maps using only the data that your phone was already collecting. These 3D maps are useful for many things, including helping your phone estimate location with more accuracy.\nWe hope this approach can replace and/or complement current methods of building 3D maps which use LIDAR or aerial photos, as the cost of these approaches can be significant when repeated often enough to keep maps up to date.\nWe’re developing different algorithms to see how they perform, and OS data is invaluable in the process. The performance of algorithms can be improved by starting with an accurate 2D map, and OS MasterMap is the definitive vector map of Great Britain which we can access under licence for academic research through EDINA’s Digimap service. Of particular use to us is OS MasterMap’s building height attribute dataset. We use it as a benchmark to measure the relative accuracy of our algorithm results.\n Photo: ©GSA, ©European GNSS Agency.\nHow it works\nStarting from a 2D building footprint provided by OS MasterMap Topography Layer, we select all the GPS signals that cross the footprint and calculate the height at which they intersect the building. This includes all of the missing signals where the satellite should have been visible but no signal was detected. We then use machine learning algorithms to estimate the height of the building from the signal patterns.\nOS Data Hub\nFor our pilot studies, we’ve been able to download and process the supporting information on an ad-hoc basis, but to scale up map production we’ll be releasing an crowdsourcing (also known as VGI or Volunteered Geographic Information) app. This is where people allow their data to be used for scientific purposes from which everyone can benefit, like a 3D map.\nAs people travel and share their data with us, we will then need to be able to automatically access data from OS about their 2D surroundings. This could be across a huge range of locations and scales that we won’t know beforehand, for example perhaps the signal blockage is due to a building close-by or a taller building further away. The OS Data Hub is ideal for this, as we can access the necessary information quickly and accurately without needing to host or maintain it. As well as using OS MasterMap information internally for our algorithms, we hope to use our results and the OS OpenData APIs in our app to generate a 3D representation. This would enable users to see a 3D map in real time and how their information is helping to improve it.\nA version of this article originally appeared here\n\n\n\n",
    "preview": {},
    "last_modified": "2021-04-27T15:04:57+01:00",
    "input_file": "osdeveloper.utf8.md"
  },
  {
    "path": "posts/2021-03-20-gnssmapper/",
    "title": "How to build a 3D map",
    "description": {},
    "author": [
      {
        "name": "Terrence Lines",
        "url": {
          "https://www.gla.ac.uk/schools/ges/staff/terencelines/": {}
        }
      }
    ],
    "date": "2021-03-20",
    "categories": [
      "GNSS-Mapping"
    ],
    "contents": "\nBuilding a 3D map\nWant to know something cool? If you have a Android smartphone you can create a 3D map using only the phone’s GNSS receiver.\n\n\n\nFigure 1: example 3D map\n\n\n\n\nWhat would be stopping you (because of course that’s something you’d want to do)? Well, I guess for most people, the problem is that creating the map would require some working knowledge of all the below:  1) GNSS systems  2) GIS / geospatial data science  3) computer vision, in particular multi-view stereo\nThis is your lucky day - we’ve put together a python package that covers all the above, as part of our commitment towards an open approach to science. Even if you have no knowledge, you can use our package to generate a map, and see how well it works or what you can use it for. Or if you have an interest in one of the fields, you can test out different ideas and see how map production is affected, without needing to go too deeply into the other areas.\nGrab the package and documentation and read on.\nMaking your first map\nSo first off, install the package using pip, but taking care to follow our instructions (this is probably the most difficult bit of the tutorial).\nObtaining GNSS data\nFor most people, the best place to obtain GNSS data is from their phone. Most smartphones have internal GNSS receivers, and phones running the Android operating system are able to access the underlying data straightforwardly. Unfortunately Apple phones do not have a similar functionality. The following steps will allow Android users to record data.\nObtain GnssLogger for your phone from the Android Play store. This is a Google developed app for showcasing the ability of using GNSS data.\nOnce installed, open the app and navigate to the Settings tab. Select the toggles for Location and Measurements. This allows the app to record both the signal data and the phone’s position estimates (based on the gnss receiver as well as any additional information available to the phone).\nThen navigate to the Log tabscreen and click ‘Start Log’ to begin recording. Once you have enough data, click ‘Stop & Send’ to save onto your phone or share directly in a csv (comma separated file) format.\nPreprocessing GNSS data into input for a mapping algorithm\nBefore applying the data to a mapping algorithm, it must be processed into a suitable form, and GnssMapper provides the necessary tools to be able to do that. First we parse the output from GNSSLogger into a Receiverpoints format. This is a dataframe of recorded signals with two columns:\ngeometry - a 3D point, representing the receivers position in space\ntime - the time (in UTC) that the signal was received\nThe dataframe will also include all the various raw data that GNSSLogger outputs (as described in the Android documentation) but for now, lets focus on two key ones:\nsvid - satellite identifier (svid)\nCn0DbHz - The Carrier-to-Noise ratio, which is a measure of signal strength.\n    >>> import gnssmapper as gm\n    # Replace the filepath with your saved GNSSLogger file.\n    >>> log = gm.read_gnsslogger(\"./examplefiles/gnss_log_2020_02_11_08_49_29.txt\")\n    >>> log[['svid','time','Cn0DbHz','geometry']].head()\n        svid                          time    Cn0DbHz                               geometry\n    0  G02 2020-02-11 08:49:27.999559028   22.34062  POINT Z (-0.13414 51.52471 114.85894)\n    1  G05 2020-02-11 08:49:27.999559028  26.320181  POINT Z (-0.13414 51.52471 114.85894)\n    2  G07 2020-02-11 08:49:27.999559028  47.322662  POINT Z (-0.13414 51.52471 114.85894)\n    3  G09 2020-02-11 08:49:27.999559028  35.282738  POINT Z (-0.13414 51.52471 114.85894)\n    4  G13 2020-02-11 08:49:27.999559028  22.712795  POINT Z (-0.13414 51.52471 114.85894)\nThe Receiverpoints object is a GeoPandas DataFrame, so can use all its normal methods for geospatial data handling. If you are new to GeoPandas, you may wish to familarise yourself with its core concepts.\nAmending Receiverpoint positions\nThe receiver positions are those generated from the GNSS receiver, but you may want to input your own depending on their accuracy. The GNSS mapping algorithm is particularly sensitive to the receiver’s recorded altitude, which can often be inaccurate due to various reasons relating to satellite geometry.\nAs an example we are going to double check our elevation estimates by using a Digital Terrain Model (DTM)obtained here produced by the UK’s Environment Agency and available under an Open Government Licence. This gives ground level heights for the majority of the UK. This requires some geospatial processing of raster data, but it isn’t a core part of the tutorial, so you can skip to the next section if it’s not of immediate interest.\nFirst, the Receiverpoints must be reprojected to match the coordinate reference system of the digital terrain model (British National Grid with Ordnance Datum Nelwyn)\n    >>> gm.geo.pyproj.network.set_network_enabled(True)\n    # Ensures the most accurate CRS transform is available, otherwise WGS84 doesn't always transform Z coordinate to BNG correctly\n    >>> log_BNG = gm.geo.to_crs(log,7405)\n    >>> log_BNG.crs\n    <Compound CRS: EPSG:7405>\n    Name: OSGB 1936 / British National Grid + ODN height\n    Axis Info [cartesian|vertical]:\n    - E[east]: Easting (metre)\n    - N[north]: Northing (metre)\n    - H[up]: Gravity-related height (metre)\n    Area of Use:\n    - name: United Kingdom (UK) - Great Britain onshore - England and Wales - mainland; Scotland - mainland and Inner Hebrides.\n    - bounds: (-7.06, 49.93, 1.8, 58.71)\n    Datum: OSGB 1936\n    - Ellipsoid: Airy 1830\n    - Prime Meridian: Greenwich\n    Sub CRS:\n    - OSGB 1936 / British National Grid\n    - ODN height\nNow lookup ground height values using the DTM and substitute back into the ReceiverPoints dataframe\n    >>> import rasterio\n    >>> dtm = rasterio.open(\"./examplefiles/LIDAR-DTM-1m-2019-TQ28se/TQ28se_DTM_1m.tif\")\n    >>> height = dtm.read(1)\n    # get the raster row and colum numbers corresponding to the point locations\n    >>> row,col = dtm.index(log_BNG.geometry.x,log_BNG.geometry.y)\n    #lookup terrain height for each point and add 1 metre to account for phone held at waist height.\n    >>> new_z = height[row, col] + 1 \n    >>> import geopandas as gpd\n    >>> log_BNG.geometry = gpd.points_from_xy(log_BNG.geometry.x,log_BNG.geometry.y,new_z+1)\n    >>> log_BNG[['svid','time','Cn0DbHz','geometry']].head()\n      svid                          time    Cn0DbHz                                geometry\n    0  G02 2020-02-11 08:49:27.999559028   22.34062  POINT Z (529537.953 182293.216 29.080)\n    1  G05 2020-02-11 08:49:27.999559028  26.320181  POINT Z (529537.953 182293.216 29.080)\n    2  G07 2020-02-11 08:49:27.999559028  47.322662  POINT Z (529537.953 182293.216 29.080)\n    3  G09 2020-02-11 08:49:27.999559028  35.282738  POINT Z (529537.953 182293.216 29.080)\n    4  G13 2020-02-11 08:49:27.999559028  22.712795  POINT Z (529537.953 182293.216 29.080)\nOnce we are happy with our Receiverpoint dataset, it’s time to move on to processing it further.\nGenerating Observations\nThe next step is to add information about satellite positions, including satellites where the signal wasn’t received but which should have been visible. For the rest of the tutorial, we’ll use a receiverpoint file created as part of a pilot study.\n    >>> import geopandas as gpd\n    >>> pilot_log = gpd.read_file(\"zip://./examplefiles/pilot_study.geojson.zip\", driver=\"GeoJSON\")\n    >>> pilot_log.time = pilot_log.time.astype('datetime64')\n    >>> pilot_log.svid = pilot_log.svid.astype('string')\n    # Correcting the altitudes\n    >>> pilot_log.geometry=gpd.points_from_xy(pilot_log.geometry.x,pilot_log.geometry.y,80)\nIn order to retrieve information on the historic positions of satellites, GnssMapper downloads data from the ESA. Downloading and parsing the data is slow, so a local cache is generated, and loaded into memory as required.\n    >>> obs = gm.observe(pilot_log)\n    {'2020063', '2020045', '2020066', '2020044'} orbits are missing and must be created.\n    downloading sp3 file for 2020063.\n    creating 2020063 orbit.\n    saving 2020063 orbit.\n    ....\n    >>> obs.head()\n                      time svid  Cn0DbHz                                           geometry\n    0  2020-03-03T10:20:19  C10      NaN  LINESTRING Z (3976545.346 -9309.219 4970128.21...\n    1  2020-03-03T10:20:19  C14      NaN  LINESTRING Z (3976545.346 -9309.219 4970128.21...\n    2  2020-03-03T10:20:19  C21      NaN  LINESTRING Z (3976545.346 -9309.219 4970128.21...\n    3  2020-03-03T10:20:19  C22      NaN  LINESTRING Z (3976545.346 -9309.219 4970128.21...\n    4  2020-03-03T10:20:19  C24      NaN  LINESTRING Z (3976545.346 -9309.219 4970128.21...\nThese are now a set of Observations which can be used in the mapping algorithm. Again this a GeoPandas dataframe, and is quite similar to the Receiverpoints but the geometry has changed from points (representing the receiver position) to a series of rays between the receiver and satellite. Rays are straight lines which represents a direct path from the receiver towards the relevant satellite. They are truncated at 1km in length, in order to minimise inaccuracy upon transformation to a projected CRS (a straight line in a geographic CRS is not a straightline in a projected CRS).\nThere are also many more observations, corresponding to the unobserved satellites, which are recorded with a missing signal strength (Cn0DbHz is NaN).\nHaving processed the data we can save it for analysis. It can be read using GeoPandas, with some minimal processing to ensure datatypes have been read correctly::\n>>> obs.to_file('./examplefiles/obs.geojson', driver=\"GeoJSON\")\n>>> test = gpd.read_file('./examplefiles/obs.geojson')\n>>> test.time = test.time.astype('datetime64')\n>>> test.svid = test.svid.astype('string')\nApplying the Mapping Algorithm\nThe expected map form is another GeoPandas DataFrame, with the geometry now being a collection of 2D polygons, along with a corresponding height column. This represents a simple LOD1 3D map. It can be initialised from a 2D map with a blank height column. For the pilot study, the 2D map was downloaded from Ordnance Survey’s Open Map Local and a building of interest was picked out.\n    >>> mymap = gpd.read_file('./examplefiles/OS OpenMap Local (ESRI Shape File) TQ/data/TQ_Building.shp', rows=slice(398502, 398503))\n    # We have to add a height column and ensure the polygons are only two dimensional. \n    >>> mymap=gm.geo.drop_z(mymap)\n    >>> mymap['height'] = 0\n    # The original map CRS is BNG without a vertical datum, we add one so the CRS transform is vaid\n    >>> mymap = mymap.set_crs(7405,allow_override=True)\n    >>> mymap\n                                         ID  FEATCODE                                           geometry  height\n    0  000BEF1D-8DAD-4FA5-8EE9-0740DF8C2908     15014  POLYGON ((529673.640 182194.510, 529665.210 18...       0\nGiven a map of floorplates and a set of observations, the height of map elements can be predicted from the observations. GnssMapper implements a bootstrapped four-parameter logistic regression. This fits a four-parameter logistic regression to the data and estimates the height based on model parameters.\n    >>> gm.predict(mymap,obs)\n       lower_bound  mid_point  upper_bound\n    0    47.443124  52.645458    57.847791\nThese are all absolute heights rather than relative to ground level, which is around 30 metres in this case - so the building is in the order of 20 metres high. How does this compare to the ground truth? Ordnance Survey data suggests that the absolute height of the building is 55m at the very highest point, and that other parts of the roof are at 47m, so this seems like the algorith has worked relatively well.\nHow does the algorithm work?\nAt a very high level, the algorithm uses the Cn0DbHz feature to classify signals as LOS/NLOS. If there is a building blocking the ray, the signal will be missing or weaker (as it is actually received after being reflected off antoher building). The intersection height is also a predictor for LOS - if it is above the actual height of the building the signal should be LOS. It’s actually more complicated than this because Cn0DbHz is not particularly accurate at classifying signals, and the interesection height is also inaccurate due to reliability of the receiver position. Nevertheless, it’s possible to fit a type of logistic regression for signal height against signal class, and the model parameters relate to the building’s height.\nWe can explore the algorithm further. First we prepare the dataset of intersection heights and fit the models.\n\n    >>> data = gm.algo.prepare_data(mymap, obs)\n    >>> data.head()\n            0  Cn0DbHz\n    0  46.157860      NaN\n    1  63.463573      NaN\n    2  64.654790      NaN\n    3  35.518055      NaN\n    4  36.434540      NaN\n    >>> learnt_parameters = gm.algo.fit(data[0], data['Cn0DbHz'])\n    # These are a timeseries of evolving parameters from two link height and signal strnegth classifiers. We are interested in their final states.\n    >>> signalstrength_parameters = learnt_parameters [-1, 0]\n    >>> height_parameters = learnt_parameters[-1, 1]\nNext we see how the proportion of LOS signals varies with height.\n    >>> import pandas as pd\n    >>> bins = pd.cut(data[0], bins=range(30, 81))\n    >>> from scipy.special import expit, logit\n    >>> def inv(param, z):\n    ...   return param[2] + logit((z-param[3])/(param[0] - param[3]))/param[1]\n    >>> pred = data['Cn0DbHz']>inv(signalstrength_parameters,0.5)\n    >>> proportion = pred.groupby(bins).sum() / pred.groupby(bins).count()\nFinally we plot this along with the fitted 4-parameter logistic regression.\n    >>> import matplotlib.pyplot as plt\n    >>> import numpy as np\n    >>> fig, ax = plt.subplots()\n    >>> x = np.linspace(30.5, 80.5, 50)\n    >>> def f(param,z):\n    ...    return param[3] + (param[0] - param[3]) * expit(param[1] * (z - param[2]))\n    >>> z = f(height_parameters,x)\n    >>> ax.plot(x, proportion, 'o', color='tab:brown')\n    >>> ax.plot(x, z)\n    >>> ax.set_xlabel('intersection height (m)')\n    >>> ax.set_ylabel('Proportion LOS')\n    >>> fig.suptitle('logistic regression on signal classification')\n    >>> plt.show()\n\n\n\nFigure 2: Graph of algorithm\n\n\n\nThe predicted height relates to the position and steepness of the slope of the graph.\n\n\n\n",
    "preview": "posts/2021-03-20-gnssmapper/gnss.png",
    "last_modified": "2021-04-27T15:08:15+01:00",
    "input_file": "gnssmapper.utf8.md"
  },
  {
    "path": "posts/2021-04-21-we-are-writing-a-systematic-review-about-vgi/",
    "title": "We are writing a systematic review about VGI",
    "description": {},
    "author": [
      {
        "name": "Hyesop Shin",
        "url": {}
      }
    ],
    "date": "2021-02-27",
    "categories": [
      "VGI"
    ],
    "contents": "\nReview\nThe crowdsourcing project has kicked off a few months ago, but sadly due to COVID19, we haven’t been able to work on the fun bits yet. Yes, data crowdsourcing. We know that due to the current circumstances, we have to sadly leave the active work slightly behind and do some desk working first. As a result, we decided to write a review the literature to see what is going on in this discipline.\nYou may have noticed that we are writing a literature review but systematically writing it. What is the difference? Compared to the convential literature review where most authors cite articles and books as per their purpose, a systematic review is written in a more objective way:  1) formulating questions according to the protocol  2) showing including and excluding criteria before filtering relevant studies  3) evaluate the quality of the selected studies\nWe understand that by doing a systematic review will enable us maximum information with minimally biased criteria with courtesy to the protocol. Also the transparency is another imporant asset to that.\nWe set our research aim to identify and analyse the main components of under-represented participants in various VGI projects and the outlook to encourage diverse participation in future geospatial crowdsourcing. The main question is shown below:\n\nDoes the contribution of under-represented volunteers (participants) more likely to create diverse outcomes in VGI projects when compared with the socially biased environment?\n\nWe have set our research objective and questions, and are currently documenting our selection criteria that looks something like this document (follow link).\nSlides\nWe would be delighted to share more of our current work and receive feedback.\nYou can click Present button in the slide below or simply follow the link (visit URL).\n\n\n\n\nPlease have a look at the slides for more details and let us know if you have any questions.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-04-27T14:33:25+01:00",
    "input_file": {}
  }
]
